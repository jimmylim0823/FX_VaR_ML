{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9440dcf5-a4e9-439a-a74f-10c93797607a",
   "metadata": {},
   "source": [
    "# Estimating VaR in EURUSD from IV using ML and QR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01243841-1668-4fcb-a6bf-8c8f1bbad4a7",
   "metadata": {},
   "source": [
    "## Modeling-Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b66d8-517b-4b34-b72d-69181ac00ec4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87e1d4b-e1aa-4c24-9e2a-5bc68003d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9763ee0-5184-4a58-8e7f-b44b542976be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_scale.pickle', 'rb') as f:\n",
    "    data_scale = pickle.load(f)\n",
    "\n",
    "with open('model_qr.pickle', 'rb') as f:\n",
    "    model_qr = pickle.load(f)\n",
    "\n",
    "with open('model_qr2.pickle', 'rb') as f:\n",
    "    model_qr2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e1146-2d6f-47b2-b114-64263774488b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### QR-IM generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebb625c-7363-44df-a671-b3f6600ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.01, 0.025, 0.05, 0.95, 0.975, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9066be47-a1da-4cc5-acf5-0658a9bff951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spot_is_x = data_scale['df_spot_is'].iloc[:,:-1]\n",
    "df_spot2_is_x = data_scale['df_spot2_is'].iloc[:,:-1]\n",
    "df_spread_is_x = data_scale['df_spread_is'].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aecc262-fea0-439d-ac79-460a57ea01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_qr = dict()\n",
    "for quantile, model in model_qr.items():\n",
    "    predict_qr[quantile] = model.predict(df_spot_is_x)\n",
    "\n",
    "predict_qr2 = dict()\n",
    "for quantile, model in model_qr2.items():\n",
    "    predict_qr2[quantile] = model.predict(df_spot2_is_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742c68f-6741-4193-819d-8060d6452dc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Random Forest: QR-IM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1904ce6-afcc-45bd-83a8-80a7389b331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10296ba9-781e-4290-b8e7-d6a4b0354a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Random Forest-Quantile 0.01 ######\n",
      "Split 1 MSE: 6.967384580720063e-06\n",
      "Split 2 MSE: 1.0629873652852539e-05\n",
      "Split 3 MSE: 6.30690548150144e-06\n",
      "Split 4 MSE: 3.972141033007014e-06\n",
      "Split 5 MSE: 2.9526196250320914e-06\n",
      "Quantile 0.01 Final MSE: 2.3936719104996926e-07\n",
      "###### Random Forest-Quantile 0.025 ######\n",
      "Split 1 MSE: 7.545363440117452e-06\n",
      "Split 2 MSE: 7.763754519647189e-06\n",
      "Split 3 MSE: 4.706107619585811e-06\n",
      "Split 4 MSE: 1.647826825773993e-06\n",
      "Split 5 MSE: 1.5268991938127748e-06\n",
      "Quantile 0.025 Final MSE: 1.4786550674171527e-07\n",
      "###### Random Forest-Quantile 0.05 ######\n",
      "Split 1 MSE: 2.160494278812935e-06\n",
      "Split 2 MSE: 2.7714713738416393e-06\n",
      "Split 3 MSE: 1.952839148014563e-06\n",
      "Split 4 MSE: 1.1923769809691968e-06\n",
      "Split 5 MSE: 8.830360438086358e-07\n",
      "Quantile 0.05 Final MSE: 6.34971200952708e-08\n",
      "###### Random Forest-Quantile 0.95 ######\n",
      "Split 1 MSE: 2.3577080683673276e-06\n",
      "Split 2 MSE: 1.8650947816326237e-06\n",
      "Split 3 MSE: 2.2685331582898964e-06\n",
      "Split 4 MSE: 1.1548634795030172e-06\n",
      "Split 5 MSE: 9.878656648679217e-07\n",
      "Quantile 0.95 Final MSE: 6.172168140364206e-08\n",
      "###### Random Forest-Quantile 0.975 ######\n",
      "Split 1 MSE: 3.3868823736669152e-06\n",
      "Split 2 MSE: 1.0507421094595098e-06\n",
      "Split 3 MSE: 2.8567760506488565e-06\n",
      "Split 4 MSE: 9.87089559827896e-07\n",
      "Split 5 MSE: 1.0275597894623587e-06\n",
      "Quantile 0.975 Final MSE: 8.025758449810003e-08\n",
      "###### Random Forest-Quantile 0.99 ######\n",
      "Split 1 MSE: 5.620741040288065e-06\n",
      "Split 2 MSE: 1.957018544969727e-06\n",
      "Split 3 MSE: 5.135529476919334e-06\n",
      "Split 4 MSE: 1.3147020324458121e-06\n",
      "Split 5 MSE: 1.7070322997561231e-06\n",
      "Quantile 0.99 Final MSE: 2.3892940114564015e-07\n"
     ]
    }
   ],
   "source": [
    "rf_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### Random Forest-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = predict_qr[quantile]\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "       'n_estimators': [50, 100, 200],\n",
    "       'max_depth': [None, 10, 20],\n",
    "       'min_samples_split': [2, 5, 10],\n",
    "       'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # random forest regression\n",
    "        rf = RandomForestRegressor()\n",
    "        grid_search = GridSearchCV(rf,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_rf = grid_search.best_estimator_\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        best_scores.append(mse)\n",
    "        print(f'Split {split} MSE: {mse}')\n",
    "\n",
    "    # final rf model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_rf = RandomForestRegressor(**best_params[-1])\n",
    "    final_rf.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_rf.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f'Quantile {quantile} Final MSE: {mse}')\n",
    "    \n",
    "    # append final model\n",
    "    rf_models[quantile] = final_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614d61e2-0d9f-4899-ac79-ce121b49b815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_models.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_models, 'rf_models.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959c5b5-2775-4c0a-b69b-dd0bcae1891f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### XGBoost(1): QR-IM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe1e013-bb38-4c23-922f-8573a72c80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57bbc3b2-8cfc-4e40-9c63-a3d6a319c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### XGBoost 1-Quantile 0.01 ######\n",
      "Split 1 MSE: 4.364300606291534e-06\n",
      "Split 2 MSE: 6.134583748193137e-06\n",
      "Split 3 MSE: 3.897691646392137e-06\n",
      "Split 4 MSE: 1.3767724225202197e-06\n",
      "Split 5 MSE: 1.5200019564135488e-06\n",
      "Quantile 0.01 Final MSE: 1.0239899822086427e-07\n",
      "###### XGBoost 1-Quantile 0.025 ######\n",
      "Split 1 MSE: 4.350092596191196e-06\n",
      "Split 2 MSE: 4.792770046641507e-06\n",
      "Split 3 MSE: 4.439026016672763e-06\n",
      "Split 4 MSE: 1.1942631912543654e-06\n",
      "Split 5 MSE: 1.207309349108191e-06\n",
      "Quantile 0.025 Final MSE: 1.5844692590847445e-07\n",
      "###### XGBoost 1-Quantile 0.05 ######\n",
      "Split 1 MSE: 1.2614027851460886e-06\n",
      "Split 2 MSE: 1.1432090467277545e-06\n",
      "Split 3 MSE: 8.530419506532179e-07\n",
      "Split 4 MSE: 3.2879262642173264e-07\n",
      "Split 5 MSE: 2.7325893091697286e-07\n",
      "Quantile 0.05 Final MSE: 5.5420398408488253e-08\n",
      "###### XGBoost 1-Quantile 0.95 ######\n",
      "Split 1 MSE: 1.6053545860510248e-06\n",
      "Split 2 MSE: 7.907917281273657e-07\n",
      "Split 3 MSE: 1.002558896903793e-06\n",
      "Split 4 MSE: 3.091210907570536e-07\n",
      "Split 5 MSE: 2.582016742332679e-07\n",
      "Quantile 0.95 Final MSE: 3.041334298589534e-08\n",
      "###### XGBoost 1-Quantile 0.975 ######\n",
      "Split 1 MSE: 2.7241134251473827e-06\n",
      "Split 2 MSE: 5.883999268218905e-07\n",
      "Split 3 MSE: 1.3222665845341514e-06\n",
      "Split 4 MSE: 4.3896945063564125e-07\n",
      "Split 5 MSE: 2.0697621727506549e-07\n",
      "Quantile 0.975 Final MSE: 3.200509595671293e-08\n",
      "###### XGBoost 1-Quantile 0.99 ######\n",
      "Split 1 MSE: 3.198497305694398e-06\n",
      "Split 2 MSE: 1.0708250481634575e-06\n",
      "Split 3 MSE: 2.9995012849751495e-06\n",
      "Split 4 MSE: 5.438907584306228e-07\n",
      "Split 5 MSE: 3.696746412771581e-07\n",
      "Quantile 0.99 Final MSE: 7.380197698502975e-08\n"
     ]
    }
   ],
   "source": [
    "xgb1_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### XGBoost 1-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = predict_qr[quantile]\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # xgboost regression\n",
    "        xgb_reg = xgb.XGBRegressor()\n",
    "        grid_search = GridSearchCV(xgb_reg,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_xgb_reg = grid_search.best_estimator_\n",
    "        y_pred = best_xgb_reg.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        best_scores.append(mse)\n",
    "        print(f'Split {split} MSE: {mse}')\n",
    "\n",
    "    # final xgboost model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_xgb_reg = xgb.XGBRegressor(**best_params[-1])\n",
    "    final_xgb_reg.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_xgb_reg.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f'Quantile {quantile} Final MSE: {mse}')\n",
    "    \n",
    "    # append final model\n",
    "    xgb1_models[quantile] = final_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7b4b16-8439-4e9f-9b4b-376d32849444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb1_models.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb1_models, 'xgb1_models.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb8054-a842-4754-879f-c5b7e98f5fbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### XGBoost(2): Gradient Boosting generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e598282-9dae-41bd-8550-26e5cbfca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111428c-8fd1-4a39-8ce4-726f0ae16910",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Gradient Boosting Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aaf93f7-c8b3-48bb-a1e2-5a3b4ed7c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28058e-927f-467b-bcbe-fa7428302928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 Quantile Split 1 Pinball: 0.00017546812646003086\n",
      "0.025 Quantile Split 1 Pinball: 0.00036586692358215515\n",
      "0.05 Quantile Split 1 Pinball: 0.0006023285584226296\n",
      "0.95 Quantile Split 1 Pinball: 0.0006093254469747829\n",
      "0.975 Quantile Split 1 Pinball: 0.00034987287199872137\n",
      "0.99 Quantile Split 1 Pinball: 0.00015828310517877568\n",
      "0.01 Quantile Split 2 Pinball: 0.00014323809157300478\n",
      "0.025 Quantile Split 2 Pinball: 0.00030395676314739524\n",
      "0.05 Quantile Split 2 Pinball: 0.0004828984806873742\n",
      "0.95 Quantile Split 2 Pinball: 0.0005411609818277345\n",
      "0.975 Quantile Split 2 Pinball: 0.0003172619091624715\n",
      "0.99 Quantile Split 2 Pinball: 0.00014534779084667712\n",
      "0.01 Quantile Split 3 Pinball: 0.00024169082302465523\n",
      "0.025 Quantile Split 3 Pinball: 0.0004896385552133623\n",
      "0.05 Quantile Split 3 Pinball: 0.0008298115872578058\n",
      "0.95 Quantile Split 3 Pinball: 0.0008598591885771985\n",
      "0.975 Quantile Split 3 Pinball: 0.0005023659198649535\n",
      "0.99 Quantile Split 3 Pinball: 0.00023484645186014347\n",
      "0.01 Quantile Split 4 Pinball: 0.0002475386348015063\n",
      "0.025 Quantile Split 4 Pinball: 0.0004445842766535788\n",
      "0.05 Quantile Split 4 Pinball: 0.0007086624591232802\n",
      "0.95 Quantile Split 4 Pinball: 0.0005601298140522597\n",
      "0.975 Quantile Split 4 Pinball: 0.000340557992739599\n",
      "0.99 Quantile Split 4 Pinball: 0.00016912274233252432\n",
      "0.01 Quantile Split 5 Pinball: 0.0001354515164198966\n",
      "0.025 Quantile Split 5 Pinball: 0.00028213899772371455\n",
      "0.05 Quantile Split 5 Pinball: 0.0004856715050884481\n",
      "0.95 Quantile Split 5 Pinball: 0.0005753160098447222\n",
      "0.975 Quantile Split 5 Pinball: 0.0003562185883287495\n",
      "0.99 Quantile Split 5 Pinball: 0.00018679560674830073\n",
      "0.01 Quantile Final Pinball: 0.00018679560674830073\n",
      "0.025 Quantile Final Pinball: 0.00018679560674830073\n",
      "0.05 Quantile Final Pinball: 0.00018679560674830073\n",
      "0.95 Quantile Final Pinball: 0.00018679560674830073\n",
      "0.975 Quantile Final Pinball: 0.00018679560674830073\n",
      "0.99 Quantile Final Pinball: 0.00018679560674830073\n"
     ]
    }
   ],
   "source": [
    "sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "param_grid = {\n",
    "   'n_estimators': [50, 100, 200],\n",
    "   'max_depth': [3, 5, 7],\n",
    "   'learning_rate': [0.01, 0.1, 0.2],\n",
    "   'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "def pinball_loss(y_true, y_pred, quantile):\n",
    "    errors = y_true - y_pred\n",
    "    return np.maximum((quantile - 1) * errors, quantile * errors).mean()\n",
    "\n",
    "pinball_scorer = make_scorer(pinball_loss, greater_is_better=False)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "best_params = {q: [] for q in quantiles}\n",
    "best_scores = {q: [] for q in quantiles}\n",
    "\n",
    "X = df_spread_is_x\n",
    "y = data_scale['df_spread_is'].iloc[:,-1]\n",
    "\n",
    "# walk forward cv\n",
    "split = 0\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    split += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    weights_train = sample_weights[train_index]\n",
    "    weights_test = sample_weights[test_index]\n",
    "\n",
    "    for quantile in quantiles:\n",
    "        # gradient boosting quantile regressor\n",
    "        gb_quantile = GradientBoostingRegressor(loss='quantile',\n",
    "                                                alpha=quantile)\n",
    "        grid_search = GridSearchCV(gb_quantile, param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1, scoring=pinball_scorer)\n",
    "        grid_search.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params[quantile].append(grid_search.best_params_)\n",
    "        best_gb_quantile = GradientBoostingRegressor(\n",
    "            loss='quantile', alpha=quantile, **grid_search.best_params_)\n",
    "        best_gb_quantile.fit(X_train, y_train)\n",
    "        y_pred = best_gb_quantile.predict(X_test)\n",
    "        pinball = pinball_loss(y_test, y_pred, quantile)\n",
    "        best_scores[quantile].append(pinball)\n",
    "        print(f'{quantile} Quantile Split {split} Pinball: {pinball}')\n",
    "\n",
    "# append final gb model\n",
    "mean_scores = {q: np.mean(scores) for q, scores in best_scores.items()}\n",
    "\n",
    "final_models = dict()\n",
    "for quantile in quantiles:\n",
    "    final_gb_quantile = GradientBoostingRegressor(\n",
    "        loss='quantile', alpha=quantile, **best_params[quantile][-1])\n",
    "    final_gb_quantile.fit(X, y, sample_weight=sample_weights)\n",
    "    print(f'{quantile} Quantile Final Pinball: {pinball}')\n",
    "    final_models[quantile] = final_gb_quantile\n",
    "\n",
    "# generate target dataset\n",
    "predict_gb = dict()\n",
    "for quantile, model in final_models.items():\n",
    "    predict_gb[quantile] = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6b624-f2eb-4a39-944f-212ede44ebbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ecc3732-f6c9-4d25-87ed-8b31b1f01713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### XGBoost 2-Quantile 0.01 ######\n",
      "Split 1 MSE: 7.307612806749463e-08\n",
      "Split 2 MSE: 1.4021814470576e-08\n",
      "Split 3 MSE: 6.351682449351885e-08\n",
      "Split 4 MSE: 9.377528480490676e-08\n",
      "Split 5 MSE: 1.1421858027709228e-08\n",
      "Quantile 0.01 Final MSE: 1.2566056099887234e-09\n",
      "###### XGBoost 2-Quantile 0.025 ######\n",
      "Split 1 MSE: 4.848615196168912e-08\n",
      "Split 2 MSE: 5.603477355268361e-09\n",
      "Split 3 MSE: 1.388442724595969e-07\n",
      "Split 4 MSE: 4.766691227011342e-07\n",
      "Split 5 MSE: 1.19903444438093e-07\n",
      "Quantile 0.025 Final MSE: 8.01009619361447e-09\n",
      "###### XGBoost 2-Quantile 0.05 ######\n",
      "Split 1 MSE: 2.9978428062607034e-08\n",
      "Split 2 MSE: 1.6745153823134963e-08\n",
      "Split 3 MSE: 3.752973953081494e-08\n",
      "Split 4 MSE: 8.149396713161648e-08\n",
      "Split 5 MSE: 4.353449429570527e-08\n",
      "Quantile 0.05 Final MSE: 3.8288769678713434e-10\n",
      "###### XGBoost 2-Quantile 0.95 ######\n",
      "Split 1 MSE: 4.3662144994545155e-08\n",
      "Split 2 MSE: 1.7037366292774007e-08\n",
      "Split 3 MSE: 3.835885426510018e-08\n",
      "Split 4 MSE: 6.894424577070314e-09\n",
      "Split 5 MSE: 1.335705417224384e-08\n",
      "Quantile 0.95 Final MSE: 1.7785452591065413e-09\n",
      "###### XGBoost 2-Quantile 0.975 ######\n",
      "Split 1 MSE: 2.754823347177201e-08\n",
      "Split 2 MSE: 3.982889735494911e-08\n",
      "Split 3 MSE: 1.349214345711078e-07\n",
      "Split 4 MSE: 1.0975786657307905e-08\n",
      "Split 5 MSE: 1.5711454226790564e-08\n",
      "Quantile 0.975 Final MSE: 1.0253094985282005e-09\n",
      "###### XGBoost 2-Quantile 0.99 ######\n",
      "Split 1 MSE: 1.9263573855888426e-07\n",
      "Split 2 MSE: 1.7515766558187315e-08\n",
      "Split 3 MSE: 1.338008429720519e-07\n",
      "Split 4 MSE: 4.311921099929767e-08\n",
      "Split 5 MSE: 1.4494769595376818e-08\n",
      "Quantile 0.99 Final MSE: 8.770769000771651e-10\n"
     ]
    }
   ],
   "source": [
    "xgb2_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### XGBoost 2-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = pd.Series(predict_gb[quantile],\n",
    "                  index=df_spread_is_x.index)\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # xgboost regression\n",
    "        xgb_reg = xgb.XGBRegressor()\n",
    "        grid_search = GridSearchCV(xgb_reg,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_xgb_reg = grid_search.best_estimator_\n",
    "        y_pred = best_xgb_reg.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        best_scores.append(mse)\n",
    "        print(f'Split {split} MSE: {mse}')\n",
    "\n",
    "    # final xgboost model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_xgb_reg = xgb.XGBRegressor(**best_params[-1])\n",
    "    final_xgb_reg.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_xgb_reg.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f'Quantile {quantile} Final MSE: {mse}')\n",
    "    \n",
    "    # append final model\n",
    "    xgb2_models[quantile] = final_xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c83321e-89f0-4fcf-abb1-bc2aae74ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb2_models.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb2_models, 'xgb2_models.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f953d54-dd4c-46b8-a896-64778538df0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LightGBM(1): QR-IM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2208eb9e-7c84-4c4c-abf5-8bbf8cfe28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436b57c2-6b11-47ad-81d9-df7f69f25b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### LightGBM 1-Quantile 0.01 ######\n",
      "Split 1 MSE: 1.3111320254944707e-05\n",
      "Split 2 MSE: 4.668214740576395e-06\n",
      "Split 3 MSE: 4.525413736269189e-06\n",
      "Split 4 MSE: 1.537225588222237e-06\n",
      "Split 5 MSE: 1.551974870308574e-06\n",
      "Quantile 0.01 Final MSE: 1.8704468673037263e-07\n",
      "###### LightGBM 1-Quantile 0.025 ######\n",
      "Split 1 MSE: 8.132928402712987e-06\n",
      "Split 2 MSE: 2.445318390364542e-06\n",
      "Split 3 MSE: 2.8358946708898604e-06\n",
      "Split 4 MSE: 9.274955450984581e-07\n",
      "Split 5 MSE: 8.494210879831056e-07\n",
      "Quantile 0.025 Final MSE: 6.173404246711626e-08\n",
      "###### LightGBM 1-Quantile 0.05 ######\n",
      "Split 1 MSE: 1.406540137122763e-06\n",
      "Split 2 MSE: 9.972778643679887e-07\n",
      "Split 3 MSE: 1.7183306523769235e-06\n",
      "Split 4 MSE: 3.71919204439502e-07\n",
      "Split 5 MSE: 2.5254836670255917e-07\n",
      "Quantile 0.05 Final MSE: 4.7403141491927486e-08\n",
      "###### LightGBM 1-Quantile 0.95 ######\n",
      "Split 1 MSE: 2.255398558215045e-06\n",
      "Split 2 MSE: 7.651187758643004e-07\n",
      "Split 3 MSE: 1.5225601884078053e-06\n",
      "Split 4 MSE: 3.996409711741835e-07\n",
      "Split 5 MSE: 3.1245849603239443e-07\n",
      "Quantile 0.95 Final MSE: 2.462496145344887e-08\n",
      "###### LightGBM 1-Quantile 0.975 ######\n",
      "Split 1 MSE: 1.8289924421125968e-06\n",
      "Split 2 MSE: 6.214073805846977e-07\n",
      "Split 3 MSE: 1.867520763287249e-06\n",
      "Split 4 MSE: 5.295200079820873e-07\n",
      "Split 5 MSE: 2.621368334668467e-07\n",
      "Quantile 0.975 Final MSE: 4.737341776067169e-08\n",
      "###### LightGBM 1-Quantile 0.99 ######\n",
      "Split 1 MSE: 2.616922722746015e-06\n",
      "Split 2 MSE: 1.1222672217183513e-06\n",
      "Split 3 MSE: 2.45551365731075e-06\n",
      "Split 4 MSE: 6.450914872501858e-07\n",
      "Split 5 MSE: 4.837176376132237e-07\n",
      "Quantile 0.99 Final MSE: 1.0659326200585288e-07\n"
     ]
    }
   ],
   "source": [
    "lgb1_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### LightGBM 1-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = predict_qr[quantile]\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'verbose': [-1]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # light gbm regression\n",
    "        lgb_reg = lgb.LGBMRegressor()\n",
    "        grid_search = GridSearchCV(lgb_reg,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_lgb_reg = grid_search.best_estimator_\n",
    "        y_pred = best_lgb_reg.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        best_scores.append(mse)\n",
    "        print(f'Split {split} MSE: {mse}')\n",
    "\n",
    "    # final light gbm model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_lgb_reg = lgb.LGBMRegressor(**best_params[-1])\n",
    "    final_lgb_reg.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_lgb_reg.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f'Quantile {quantile} Final MSE: {mse}')\n",
    "    \n",
    "    # append final model\n",
    "    lgb1_models[quantile] = final_lgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b178a6-e5d7-4cd9-99c3-a7589ece14ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb1_models.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgb1_models, 'lgb1_models.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f0ebd-f465-496e-bcf6-8a3e6f780547",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LightGBM(2): QR-IM Dataset with Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9515ed53-7ea4-4c3b-b7af-4cc0930bbb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### LightGBM 2-Quantile 0.01 ######\n",
      "Split 1 MSE: 6.197820868209659e-06\n",
      "Split 2 MSE: 4.099706913161765e-06\n",
      "Split 3 MSE: 3.111167447806778e-06\n",
      "Split 4 MSE: 3.223985872979535e-06\n",
      "Split 5 MSE: 1.3650058366431899e-06\n",
      "Quantile 0.01 Final MSE: 3.1940041113940153e-07\n",
      "###### LightGBM 2-Quantile 0.025 ######\n",
      "Split 1 MSE: 5.481005773353765e-06\n",
      "Split 2 MSE: 7.074666251647047e-06\n",
      "Split 3 MSE: 6.651897162353503e-06\n",
      "Split 4 MSE: 1.8804754999128199e-06\n",
      "Split 5 MSE: 1.1166626945806187e-06\n",
      "Quantile 0.025 Final MSE: 1.3996913824014615e-07\n",
      "###### LightGBM 2-Quantile 0.05 ######\n",
      "Split 1 MSE: 2.5748327614673263e-06\n",
      "Split 2 MSE: 1.4283394367405512e-06\n",
      "Split 3 MSE: 1.7929151317338928e-06\n",
      "Split 4 MSE: 1.0693043965380001e-06\n",
      "Split 5 MSE: 7.585797400817663e-07\n",
      "Quantile 0.05 Final MSE: 2.181624419145098e-07\n",
      "###### LightGBM 2-Quantile 0.95 ######\n",
      "Split 1 MSE: 1.2825291959412522e-06\n",
      "Split 2 MSE: 1.8303120629254254e-06\n",
      "Split 3 MSE: 5.422890823261235e-06\n",
      "Split 4 MSE: 2.015033496174597e-06\n",
      "Split 5 MSE: 2.0681811279646225e-06\n",
      "Quantile 0.95 Final MSE: 4.5461811190217934e-08\n",
      "###### LightGBM 2-Quantile 0.975 ######\n",
      "Split 1 MSE: 1.7797253625148088e-06\n",
      "Split 2 MSE: 1.3165709802342067e-06\n",
      "Split 3 MSE: 6.0211127453911766e-06\n",
      "Split 4 MSE: 2.18417854601204e-06\n",
      "Split 5 MSE: 1.60182326966026e-06\n",
      "Quantile 0.975 Final MSE: 5.0328301135731695e-08\n",
      "###### LightGBM 2-Quantile 0.99 ######\n",
      "Split 1 MSE: 3.4655231492483044e-06\n",
      "Split 2 MSE: 2.2436061313581936e-06\n",
      "Split 3 MSE: 9.161210185514255e-06\n",
      "Split 4 MSE: 5.291578165870423e-06\n",
      "Split 5 MSE: 1.9301057007540748e-06\n",
      "Quantile 0.99 Final MSE: 3.765332456958729e-07\n"
     ]
    }
   ],
   "source": [
    "lgb2_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### LightGBM 2-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = predict_qr2[quantile]\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'verbose': [-1]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # light gbm regression\n",
    "        lgb_reg = lgb.LGBMRegressor()\n",
    "        grid_search = GridSearchCV(lgb_reg,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_lgb_reg = grid_search.best_estimator_\n",
    "        y_pred = best_lgb_reg.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        best_scores.append(mse)\n",
    "        print(f'Split {split} MSE: {mse}')\n",
    "\n",
    "    # final light gbm model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_lgb_reg = lgb.LGBMRegressor(**best_params[-1])\n",
    "    final_lgb_reg.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_lgb_reg.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    print(f'Quantile {quantile} Final MSE: {mse}')\n",
    "    \n",
    "    # append final model\n",
    "    lgb2_models[quantile] = final_lgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e033f4-4b7d-43e8-8206-bfb896fe659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb2_models.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgb2_models, 'lgb2_models.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20d6a2-6d43-4dcb-be95-baeb5542aef3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LightGBM(3): LightGBM generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c85c61b-9462-4b90-bfda-f409b9867850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e014d35-5bc2-4acf-9378-5d59d80bbf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### LightGBM 3-Quantile 0.01 ######\n",
      "Split 1 Pinball Loss: 0.00017402617161312335\n",
      "Split 2 Pinball Loss: 0.000190481887137032\n",
      "Split 3 Pinball Loss: 0.0002219686543982026\n",
      "Split 4 Pinball Loss: 0.00026203378489943603\n",
      "Split 5 Pinball Loss: 0.00017455753212675525\n",
      "Quantile 0.01 Final Pinball Loss: 0.0004449432652286783\n",
      "###### LightGBM 3-Quantile 0.025 ######\n",
      "Split 1 Pinball Loss: 0.0003517059237107489\n",
      "Split 2 Pinball Loss: 0.0003236065446776177\n",
      "Split 3 Pinball Loss: 0.0005909626317129026\n",
      "Split 4 Pinball Loss: 0.0005299909298053481\n",
      "Split 5 Pinball Loss: 0.0003590977558146008\n",
      "Quantile 0.025 Final Pinball Loss: 0.0011894969731532186\n",
      "###### LightGBM 3-Quantile 0.05 ######\n",
      "Split 1 Pinball Loss: 0.0006441580040349503\n",
      "Split 2 Pinball Loss: 0.0005803761128867921\n",
      "Split 3 Pinball Loss: 0.0008036625639679795\n",
      "Split 4 Pinball Loss: 0.0006928668933962735\n",
      "Split 5 Pinball Loss: 0.0005694809961671982\n",
      "Quantile 0.05 Final Pinball Loss: 0.001689673011712048\n",
      "###### LightGBM 3-Quantile 0.95 ######\n",
      "Split 1 Pinball Loss: 0.012389525663121197\n",
      "Split 2 Pinball Loss: 0.00338970674265043\n",
      "Split 3 Pinball Loss: 0.0010023371664560589\n",
      "Split 4 Pinball Loss: 0.0006249405289760749\n",
      "Split 5 Pinball Loss: 0.0005863237471849722\n",
      "Quantile 0.95 Final Pinball Loss: 0.001934282414288902\n",
      "###### LightGBM 3-Quantile 0.975 ######\n",
      "Split 1 Pinball Loss: 0.008826829943650328\n",
      "Split 2 Pinball Loss: 0.020173567115502\n",
      "Split 3 Pinball Loss: 0.001676882175816356\n",
      "Split 4 Pinball Loss: 0.0003021066406817434\n",
      "Split 5 Pinball Loss: 0.5445115424986879\n",
      "Quantile 0.975 Final Pinball Loss: 0.0017015858427329642\n",
      "###### LightGBM 3-Quantile 0.99 ######\n",
      "Split 1 Pinball Loss: 0.0001522298931178749\n",
      "Split 2 Pinball Loss: 0.000556822412002046\n",
      "Split 3 Pinball Loss: 0.0004550401849148259\n",
      "Split 4 Pinball Loss: 0.0019170857803269344\n",
      "Split 5 Pinball Loss: 0.00018083387215064853\n",
      "Quantile 0.99 Final Pinball Loss: 0.0018589514531780218\n"
     ]
    }
   ],
   "source": [
    "lgb3_models = dict()\n",
    "for quantile in quantiles:\n",
    "    print(f'###### LightGBM 3-Quantile {quantile} ######')\n",
    "    X = df_spread_is_x\n",
    "    y = data_scale['df_spread_is'].iloc[:,-1]\n",
    "\n",
    "    # more sample weight toward recent data\n",
    "    sample_weights = np.arange(1,len(y)+1)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'verbose': [-1]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    best_params = []\n",
    "    best_scores = []\n",
    "\n",
    "    # walk forward cv\n",
    "    split = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # train test split\n",
    "        split += 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        weights_train = sample_weights[train_index]\n",
    "        weights_test = sample_weights[test_index]\n",
    "\n",
    "        # light gbm regression\n",
    "        lgb_reg = lgb.LGBMRegressor(objective='quantile',\n",
    "                                    alpha=quantile)\n",
    "        grid_search = GridSearchCV(lgb_reg,\n",
    "                                   param_grid,\n",
    "                                   cv=TimeSeriesSplit(n_splits=3),\n",
    "                                   n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train,\n",
    "                        sample_weight=weights_train)\n",
    "\n",
    "        # hyper-parameter tuning\n",
    "        best_params.append(grid_search.best_params_)\n",
    "        best_lgb_reg = grid_search.best_estimator_\n",
    "        y_pred = best_lgb_reg.predict(X_test)\n",
    "        pinball_loss = mean_pinball_loss(y_test, y_pred, alpha=quantile)\n",
    "        best_scores.append(pinball_loss)\n",
    "        print(f'Split {split} Pinball Loss: {pinball_loss}')\n",
    "\n",
    "    # final light gbm model\n",
    "    mean_score = np.mean(best_scores)\n",
    "    final_lgb_reg = lgb.LGBMRegressor(**best_params[-1])\n",
    "    final_lgb_reg.fit(X, y, sample_weight=sample_weights)\n",
    "    y_pred = final_lgb_reg.predict(X)\n",
    "    pinball_loss = mean_pinball_loss(y, y_pred, alpha=quantile)\n",
    "    print(f'Quantile {quantile} Final Pinball Loss: {pinball_loss}')\n",
    "    \n",
    "    # append final model\n",
    "    lgb3_models[quantile] = final_lgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d468a782-00d3-4f73-a6e3-0ac9175a224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb3_models.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgb3_models, 'lgb3_models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f23659-1ade-40a3-bee0-10b9ba860d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
